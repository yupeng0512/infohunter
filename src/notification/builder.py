"""æ¶ˆæ¯æ„å»ºå™¨

ä¸º InfoHunter å¤šæºå†…å®¹æ„å»ºé£ä¹¦é€šçŸ¥æ¶ˆæ¯ã€‚
"""

from datetime import datetime
from typing import Optional
from zoneinfo import ZoneInfo

from src.config import settings


def get_local_time() -> datetime:
    """è·å–æœ¬åœ°æ—¶é—´"""
    return datetime.now(ZoneInfo(settings.timezone))


class MessageBuilder:
    """é€šçŸ¥æ¶ˆæ¯æ„å»ºå™¨"""

    @staticmethod
    def build_content_notification(
        source: str,
        title: Optional[str],
        content: str,
        author: str,
        url: str,
        metrics: Optional[dict] = None,
        ai_analysis: Optional[dict] = None,
        subscription_name: Optional[str] = None,
    ) -> str:
        """æ„å»ºå•æ¡å†…å®¹é€šçŸ¥ (Markdown)"""
        source_emoji = {"twitter": "ğŸ¦", "youtube": "ğŸ“º"}.get(source, "ğŸ“°")
        lines = []

        if subscription_name:
            lines.append(f"ğŸ“Œ è®¢é˜…: **{subscription_name}**")
            lines.append("")

        # æ ‡é¢˜/å†…å®¹
        if title:
            lines.append(f"**{title}**")
            lines.append("")

        # æ­£æ–‡ (æˆªæ–­)
        text = content[:500] if content else ""
        if text:
            lines.append(text)
            if len(content or "") > 500:
                lines.append("...")
            lines.append("")

        # ä½œè€…å’Œäº’åŠ¨
        lines.append(f"{source_emoji} @{author}")
        if metrics:
            parts = []
            if metrics.get("likes"):
                parts.append(f"â¤ï¸ {metrics['likes']}")
            if metrics.get("retweets"):
                parts.append(f"ğŸ”„ {metrics['retweets']}")
            if metrics.get("views"):
                parts.append(f"ğŸ‘ï¸ {_format_number(metrics['views'])}")
            if metrics.get("replies"):
                parts.append(f"ğŸ’¬ {metrics['replies']}")
            if parts:
                lines.append(" | ".join(parts))

        # AI åˆ†ææ‘˜è¦
        if ai_analysis:
            lines.append("")
            lines.append("---")
            lines.append("ğŸ¤– **AI åˆ†æ**")
            if isinstance(ai_analysis, dict):
                if ai_analysis.get("summary"):
                    lines.append(f"ğŸ“ {ai_analysis['summary']}")
                if ai_analysis.get("key_points"):
                    for point in ai_analysis["key_points"][:3]:
                        lines.append(f"â€¢ {point}")
                if ai_analysis.get("importance"):
                    lines.append(f"â­ é‡è¦æ€§: {ai_analysis['importance']}/10")

        # é“¾æ¥
        if url:
            lines.append("")
            lines.append(f"[æŸ¥çœ‹åŸæ–‡]({url})")

        return "\n".join(lines)

    @staticmethod
    def build_ai_digest(
        source: str,
        title: Optional[str],
        author: str,
        url: str,
        metrics: Optional[dict] = None,
        ai_analysis: Optional[dict] = None,
        subscription_name: Optional[str] = None,
    ) -> str:
        """æ„å»º AI ç²¾é€‰æ¨é€ï¼ˆä»¥ AI åˆ†æç»“æœä¸ºæ ¸å¿ƒï¼Œä¸æ¨é€åŸæ–‡ï¼‰"""
        source_emoji = {"twitter": "ğŸ¦", "youtube": "ğŸ“º", "blog": "ğŸ“"}.get(source, "ğŸ“°")
        lines = []

        if subscription_name:
            lines.append(f"ğŸ“Œ æ¥æº: **{subscription_name}**")
        else:
            lines.append(f"{source_emoji} æ¥æº: **æ¢ç´¢å‘ç°**")
        lines.append("")

        if title:
            lines.append(f"**{title}**")
            lines.append("")

        if ai_analysis and isinstance(ai_analysis, dict):
            if ai_analysis.get("summary"):
                lines.append(f"ğŸ“ **æ‘˜è¦**: {ai_analysis['summary']}")
                lines.append("")

            if ai_analysis.get("key_points"):
                lines.append("ğŸ’¡ **æ ¸å¿ƒè§‚ç‚¹**:")
                for point in ai_analysis["key_points"][:5]:
                    lines.append(f"  â€¢ {point}")
                lines.append("")

            if ai_analysis.get("deep_analysis"):
                lines.append(f"ğŸ”¬ **æ·±åº¦åˆ†æ**: {ai_analysis['deep_analysis']}")
                lines.append("")

            if ai_analysis.get("actionable_insights"):
                lines.append("ğŸ¯ **å¯æ‰§è¡Œæ´å¯Ÿ**:")
                for insight in ai_analysis["actionable_insights"][:3]:
                    lines.append(f"  â€¢ {insight}")
                lines.append("")

            if ai_analysis.get("recommendation"):
                lines.append(f"ğŸ’¡ **å»ºè®®**: {ai_analysis['recommendation']}")
                lines.append("")

            quality = ai_analysis.get("quality_indicators", {})
            importance = ai_analysis.get("importance", 0)
            if importance:
                stars = "â­" * min(int(importance / 2), 5)
                lines.append(f"é‡è¦æ€§: {stars} ({importance}/10)")

            if quality:
                parts = []
                if quality.get("originality"):
                    parts.append(f"åŸåˆ› {quality['originality']}")
                if quality.get("depth"):
                    parts.append(f"æ·±åº¦ {quality['depth']}")
                if quality.get("credibility"):
                    parts.append(f"å¯ä¿¡ {quality['credibility']}")
                if quality.get("signal_noise_ratio"):
                    parts.append(f"ä¿¡å™ªæ¯” {quality['signal_noise_ratio']}")
                if parts:
                    lines.append(f"è´¨é‡: {' | '.join(parts)}")

            if ai_analysis.get("topics"):
                topics = ai_analysis["topics"][:5]
                lines.append(f"æ ‡ç­¾: {' '.join(f'#{t}' for t in topics)}")
        else:
            lines.append("âš ï¸ AI åˆ†ææ•°æ®å¼‚å¸¸")

        lines.append("")
        lines.append(f"{source_emoji} @{author}")
        if metrics:
            parts = []
            if metrics.get("likes"):
                parts.append(f"â¤ï¸ {metrics['likes']}")
            if metrics.get("views"):
                parts.append(f"ğŸ‘ï¸ {_format_number(metrics['views'])}")
            if parts:
                lines.append(" | ".join(parts))

        if url:
            lines.append("")
            lines.append(f"[æŸ¥çœ‹åŸæ–‡]({url})")

        return "\n".join(lines)

    @staticmethod
    def build_daily_report(
        contents: list[dict],
        date: Optional[datetime] = None,
        ai_summary: Optional[dict] = None,
    ) -> str:
        """æ„å»ºæ—¥æŠ¥æ¶ˆæ¯"""
        if date is None:
            date = get_local_time()

        date_str = date.strftime("%Y-%m-%d")
        lines = [f"ğŸ“Š **InfoHunter æ—¥æŠ¥** ({date_str})", ""]

        # ç»Ÿè®¡
        twitter_count = sum(1 for c in contents if c.get("source") == "twitter")
        youtube_count = sum(1 for c in contents if c.get("source") == "youtube")
        lines.append(f"ğŸ“ˆ ä»Šæ—¥é‡‡é›†: **{len(contents)}** æ¡")
        if twitter_count:
            lines.append(f"  ğŸ¦ Twitter: {twitter_count} æ¡")
        if youtube_count:
            lines.append(f"  ğŸ“º YouTube: {youtube_count} æ¡")
        lines.append("")

        # AI è¶‹åŠ¿æ€»ç»“
        if ai_summary:
            lines.append("---")
            lines.append("ğŸ¤– **AI è¶‹åŠ¿åˆ†æ**")
            rendered = _render_ai_summary(ai_summary)
            if rendered:
                lines.append(rendered)
            lines.append("")

        # Top å†…å®¹åˆ—è¡¨
        lines.append("---")
        lines.append("ğŸ“‹ **ç²¾é€‰å†…å®¹ Top 10**")
        lines.append("")

        for i, item in enumerate(contents[:10], 1):
            source_emoji = {"twitter": "ğŸ¦", "youtube": "ğŸ“º"}.get(
                item.get("source", ""), "ğŸ“°"
            )
            title = item.get("title") or (item.get("content", "")[:80] + "...")
            author = item.get("author", "unknown")
            url = item.get("url", "")

            line = f"{i}. {source_emoji} **{title}**"
            if author:
                line += f" - @{author}"
            if url:
                line += f" [é“¾æ¥]({url})"
            lines.append(line)

        now = get_local_time()
        lines.append("")
        lines.append(f"â° ç”Ÿæˆæ—¶é—´: {now.strftime('%Y-%m-%d %H:%M')}")

        return "\n".join(lines)

    @staticmethod
    def build_weekly_report(
        contents: list[dict],
        week_start: datetime,
        week_end: datetime,
        ai_summary: Optional[dict] = None,
    ) -> str:
        """æ„å»ºå‘¨æŠ¥æ¶ˆæ¯"""
        lines = [
            f"ğŸ“Š **InfoHunter å‘¨æŠ¥** ({week_start.strftime('%m/%d')} - {week_end.strftime('%m/%d')})",
            "",
        ]

        twitter_count = sum(1 for c in contents if c.get("source") == "twitter")
        youtube_count = sum(1 for c in contents if c.get("source") == "youtube")

        lines.append(f"ğŸ“ˆ æœ¬å‘¨é‡‡é›†: **{len(contents)}** æ¡")
        if twitter_count:
            lines.append(f"  ğŸ¦ Twitter: {twitter_count} æ¡")
        if youtube_count:
            lines.append(f"  ğŸ“º YouTube: {youtube_count} æ¡")
        lines.append("")

        # æ´»è·ƒä½œè€…ç»Ÿè®¡
        authors: dict[str, int] = {}
        for c in contents:
            author = c.get("author", "")
            if author:
                authors[author] = authors.get(author, 0) + 1
        if authors:
            top_authors = sorted(authors.items(), key=lambda x: x[1], reverse=True)[:5]
            lines.append("ğŸ‘¤ **æ´»è·ƒä½œè€… Top 5**")
            for author, count in top_authors:
                lines.append(f"  â€¢ @{author} ({count} æ¡)")
            lines.append("")

        # AI è¶‹åŠ¿åˆ†æ
        if ai_summary and isinstance(ai_summary, dict):
            lines.append("---")
            lines.append("ğŸ¤– **AI å‘¨åº¦è¶‹åŠ¿åˆ†æ**")
            if ai_summary.get("overall_summary"):
                lines.append(ai_summary["overall_summary"])

            if ai_summary.get("hot_topics"):
                lines.append("")
                lines.append("ğŸ”¥ **çƒ­é—¨è¯é¢˜**")
                for topic in ai_summary["hot_topics"][:5]:
                    if isinstance(topic, dict):
                        heat = topic.get("heat", "")
                        desc = topic.get("description", "")
                        name = topic.get("topic", str(topic))
                        heat_bar = "ğŸŸ¥" * min(int(heat), 10) if heat else ""
                        lines.append(f"  â€¢ **{name}** {heat_bar}")
                        if desc:
                            lines.append(f"    {desc}")
                    else:
                        lines.append(f"  â€¢ {topic}")

            if ai_summary.get("key_insights"):
                lines.append("")
                lines.append("ğŸ’¡ **å…³é”®æ´å¯Ÿ**")
                for insight in ai_summary["key_insights"][:5]:
                    if isinstance(insight, dict):
                        lines.append(f"  â€¢ {insight.get('insight', str(insight))}")
                    else:
                        lines.append(f"  â€¢ {insight}")

            emerging = ai_summary.get("emerging_signals") or ai_summary.get("emerging_trends")
            if emerging:
                lines.append("")
                lines.append("ğŸš€ **æ–°å…´è¶‹åŠ¿/å¼±ä¿¡å·**")
                if isinstance(emerging, list):
                    for sig in emerging[:3]:
                        if isinstance(sig, dict):
                            lines.append(f"  â€¢ {sig.get('signal', str(sig))}")
                        else:
                            lines.append(f"  â€¢ {sig}")
                elif isinstance(emerging, str):
                    lines.append(f"  {emerging}")

            sentiment_data = ai_summary.get("sentiment_overview")
            if sentiment_data:
                sentiment_map = {
                    "positive": "ğŸ˜Š ç§¯æ",
                    "negative": "ğŸ˜Ÿ æ¶ˆæ",
                    "neutral": "ğŸ˜ ä¸­æ€§",
                    "mixed": "ğŸ”€ æ··åˆ",
                }
                if isinstance(sentiment_data, dict):
                    overall = sentiment_data.get("overall", "")
                    sentiment = sentiment_map.get(overall, overall)
                    lines.append(f"ğŸ­ **æ•´ä½“æƒ…ç»ª**: {sentiment}")
                    if sentiment_data.get("breakdown"):
                        lines.append(f"  {sentiment_data['breakdown']}")
                else:
                    sentiment = sentiment_map.get(sentiment_data, sentiment_data)
                    lines.append(f"ğŸ­ **æ•´ä½“æƒ…ç»ª**: {sentiment}")

            rec = ai_summary.get("recommendation")
            if rec:
                if isinstance(rec, dict):
                    if rec.get("immediate_action"):
                        lines.append(f"ğŸ¯ **è¡ŒåŠ¨å»ºè®®**: {rec['immediate_action']}")
                    if rec.get("watch_list"):
                        lines.append(f"ğŸ‘€ **å…³æ³¨æ¸…å•**: {', '.join(rec['watch_list'][:5])}")
                else:
                    lines.append(f"ğŸ’¡ **å»ºè®®å…³æ³¨**: {rec}")
            lines.append("")

        # Top å†…å®¹
        lines.append("---")
        lines.append("ğŸ† **æœ¬å‘¨ Top 15 å†…å®¹**")
        lines.append("")

        for i, item in enumerate(contents[:15], 1):
            source_emoji = {"twitter": "ğŸ¦", "youtube": "ğŸ“º"}.get(
                item.get("source", ""), "ğŸ“°"
            )
            title = item.get("title") or (item.get("content", "")[:80] + "...")
            author = item.get("author", "")
            url = item.get("url", "")
            line = f"{i}. {source_emoji} **{title}**"
            if author:
                line += f" - @{author}"
            if url:
                line += f" [é“¾æ¥]({url})"
            lines.append(line)

        now = get_local_time()
        lines.append("")
        lines.append(f"â° ç”Ÿæˆæ—¶é—´: {now.strftime('%Y-%m-%d %H:%M')}")

        return "\n".join(lines)


    @staticmethod
    def build_briefing(
        contents: list,
        window_start: datetime,
        window_end: datetime,
        ai_trend_summary: Optional[dict] = None,
    ) -> str:
        """æ„å»ºæ—¶é—´çª—å£æ‰¹é‡ç®€æŠ¥ï¼ˆé˜¶æ®µä¸‰æ ¸å¿ƒæ¨¡æ¿ï¼‰

        Args:
            contents: Content ORM å¯¹è±¡åˆ—è¡¨ï¼ˆå·²åˆ†æçš„ï¼‰
            window_start: æ—¶é—´çª—å£å¼€å§‹
            window_end: æ—¶é—´çª—å£ç»“æŸ
            ai_trend_summary: trend_analysis Agent çš„äºŒæ¬¡æ±‡æ€»ç»“æœ
        """
        now = get_local_time()
        start_str = window_start.strftime("%m/%d %H:%M")
        end_str = window_end.strftime("%m/%d %H:%M")

        lines = [
            f"**InfoHunter ç®€æŠ¥** ({start_str} ~ {end_str})",
            f"å…± **{len(contents)}** æ¡ç²¾é€‰å†…å®¹",
            "",
        ]

        if ai_trend_summary and isinstance(ai_trend_summary, dict):
            lines.append("---")
            lines.append("**AI è¶‹åŠ¿æ€»è§ˆ**")

            if ai_trend_summary.get("overall_summary"):
                lines.append(ai_trend_summary["overall_summary"])
                lines.append("")

            if ai_trend_summary.get("hot_topics"):
                lines.append("**çƒ­ç‚¹è¯é¢˜**")
                for topic in ai_trend_summary["hot_topics"][:5]:
                    if isinstance(topic, dict):
                        name = topic.get("topic", str(topic))
                        desc = topic.get("description", "")
                        heat = topic.get("heat", 0)
                        heat_bar = "â– " * min(int(heat), 10) if heat else ""
                        lines.append(f"  â€¢ **{name}** {heat_bar}")
                        if desc:
                            lines.append(f"    {desc}")
                    else:
                        lines.append(f"  â€¢ {topic}")
                lines.append("")

            if ai_trend_summary.get("key_insights"):
                lines.append("**å…³é”®æ´å¯Ÿ**")
                for insight in ai_trend_summary["key_insights"][:5]:
                    if isinstance(insight, dict):
                        lines.append(f"  â€¢ {insight.get('insight', str(insight))}")
                    else:
                        lines.append(f"  â€¢ {insight}")
                lines.append("")

            emerging = ai_trend_summary.get("emerging_signals") or ai_trend_summary.get("emerging_trends")
            if emerging:
                lines.append("**å¼±ä¿¡å·**")
                if isinstance(emerging, list):
                    for sig in emerging[:3]:
                        if isinstance(sig, dict):
                            lines.append(f"  â€¢ {sig.get('signal', str(sig))}")
                        else:
                            lines.append(f"  â€¢ {sig}")
                elif isinstance(emerging, str):
                    lines.append(f"  {emerging}")
                lines.append("")

            rec = ai_trend_summary.get("recommendation")
            if rec:
                if isinstance(rec, dict):
                    if rec.get("immediate_action"):
                        lines.append(f"**è¡ŒåŠ¨å»ºè®®**: {rec['immediate_action']}")
                    if rec.get("watch_list"):
                        lines.append(f"**å…³æ³¨æ¸…å•**: {', '.join(rec['watch_list'][:5])}")
                else:
                    lines.append(f"**å»ºè®®å…³æ³¨**: {rec}")
                lines.append("")

        lines.append("---")
        lines.append("**ç²¾é€‰å†…å®¹**")
        lines.append("")

        for i, c in enumerate(contents[:20], 1):
            source_emoji = {"twitter": "ğŸ¦", "youtube": "ğŸ“º", "blog": "ğŸ“"}.get(
                getattr(c, "source", "") if hasattr(c, "source") else c.get("source", ""),
                "ğŸ“°",
            )
            title = (
                getattr(c, "title", None) if hasattr(c, "title") else c.get("title")
            )
            author = (
                getattr(c, "author", "") if hasattr(c, "author") else c.get("author", "")
            )
            url = (
                getattr(c, "url", "") if hasattr(c, "url") else c.get("url", "")
            )
            ai = (
                getattr(c, "ai_analysis", None) if hasattr(c, "ai_analysis") else c.get("ai_analysis")
            )

            if not title:
                content_text = getattr(c, "content", "") if hasattr(c, "content") else c.get("content", "")
                title = (content_text[:60] + "...") if content_text else "æ— æ ‡é¢˜"

            importance = 0
            summary = ""
            if ai and isinstance(ai, dict):
                importance = ai.get("importance", 0)
                summary = ai.get("summary", "")

            stars = "â­" * min(int(importance / 2), 5) if importance else ""
            line = f"{i}. {source_emoji} **{title}**"
            if author:
                line += f" @{author}"
            if stars:
                line += f" {stars}"
            lines.append(line)

            if summary:
                lines.append(f"   {summary}")

            if url:
                lines.append(f"   [åŸæ–‡]({url})")
            lines.append("")

        lines.append(f"â° {now.strftime('%Y-%m-%d %H:%M')}")
        return "\n".join(lines)


def _render_ai_summary(ai_summary) -> str:
    """æ¸²æŸ“ AI è¶‹åŠ¿åˆ†æä¸º Markdown æ–‡æœ¬

    å…¼å®¹å¤šç§ ai_summary æ ¼å¼:
      - dict with overall_summary / hot_topics / key_insights (trend prompt)
      - dict with raw_response (extract_json fallback)
      - str (plain text)
    """
    if isinstance(ai_summary, str):
        return ai_summary

    if not isinstance(ai_summary, dict):
        return str(ai_summary) if ai_summary else ""

    # å¦‚æœæ˜¯ extract_json å›é€€çš„ raw_response
    if "raw_response" in ai_summary and len(ai_summary) == 1:
        raw = ai_summary["raw_response"]
        return raw[:2000] if isinstance(raw, str) else str(raw)[:2000]

    parts: list[str] = []

    if ai_summary.get("overall_summary"):
        parts.append(ai_summary["overall_summary"])

    if ai_summary.get("hot_topics"):
        parts.append("")
        parts.append("ğŸ”¥ **çƒ­é—¨è¯é¢˜**")
        for topic in ai_summary["hot_topics"][:5]:
            if isinstance(topic, dict):
                name = topic.get("topic", str(topic))
                heat = topic.get("heat", 0)
                heat_bar = "ğŸŸ¥" * min(int(heat), 10) if heat else ""
                desc = topic.get("description", "")
                parts.append(f"â€¢ **{name}** {heat_bar}")
                if desc:
                    parts.append(f"  {desc}")
            else:
                parts.append(f"â€¢ {topic}")

    if ai_summary.get("key_insights"):
        parts.append("")
        parts.append("ğŸ’¡ **å…³é”®æ´å¯Ÿ**")
        for insight in ai_summary["key_insights"][:5]:
            if isinstance(insight, dict):
                text = insight.get("insight", str(insight))
                parts.append(f"â€¢ {text}")
            else:
                parts.append(f"â€¢ {insight}")

    if ai_summary.get("emerging_signals"):
        parts.append("")
        parts.append("ğŸ“¡ **æ–°å…´ä¿¡å·**")
        for sig in ai_summary["emerging_signals"][:3]:
            if isinstance(sig, dict):
                parts.append(f"â€¢ {sig.get('signal', str(sig))}")
            else:
                parts.append(f"â€¢ {sig}")

    rec = ai_summary.get("recommendation")
    if rec and isinstance(rec, dict):
        if rec.get("immediate_action"):
            parts.append("")
            parts.append(f"ğŸ¯ **è¡ŒåŠ¨å»ºè®®**: {rec['immediate_action']}")
        if rec.get("watch_list"):
            parts.append(f"ğŸ‘€ **å…³æ³¨æ¸…å•**: {', '.join(rec['watch_list'][:5])}")

    if not parts:
        # å…œåº•: å¦‚æœæ‰€æœ‰å·²çŸ¥å­—æ®µéƒ½ä¸ºç©ºï¼Œç›´æ¥æ¸²æŸ“æ‰€æœ‰æœ‰å€¼çš„å­—æ®µ
        for k, v in ai_summary.items():
            if v and k != "raw_response":
                parts.append(f"**{k}**: {str(v)[:300]}")

    return "\n".join(parts)


def _format_number(n: int) -> str:
    """æ ¼å¼åŒ–æ•°å­— (1000 -> 1K, 1000000 -> 1M)"""
    if n >= 1_000_000:
        return f"{n / 1_000_000:.1f}M"
    if n >= 1_000:
        return f"{n / 1_000:.1f}K"
    return str(n)
