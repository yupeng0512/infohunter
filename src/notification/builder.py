"""æ¶ˆæ¯æ„å»ºå™¨

ä¸º InfoHunter å¤šæºå†…å®¹æ„å»ºé£ä¹¦é€šçŸ¥æ¶ˆæ¯ã€‚
"""

from datetime import datetime
from typing import Optional
from zoneinfo import ZoneInfo

from src.config import settings


def get_local_time() -> datetime:
    """è·å–æœ¬åœ°æ—¶é—´"""
    return datetime.now(ZoneInfo(settings.timezone))


class MessageBuilder:
    """é€šçŸ¥æ¶ˆæ¯æ„å»ºå™¨"""

    @staticmethod
    def build_content_notification(
        source: str,
        title: Optional[str],
        content: str,
        author: str,
        url: str,
        metrics: Optional[dict] = None,
        ai_analysis: Optional[dict] = None,
        subscription_name: Optional[str] = None,
    ) -> str:
        """æ„å»ºå•æ¡å†…å®¹é€šçŸ¥ (Markdown)"""
        source_emoji = {"twitter": "ğŸ¦", "youtube": "ğŸ“º"}.get(source, "ğŸ“°")
        lines = []

        if subscription_name:
            lines.append(f"ğŸ“Œ è®¢é˜…: **{subscription_name}**")
            lines.append("")

        # æ ‡é¢˜/å†…å®¹
        if title:
            lines.append(f"**{title}**")
            lines.append("")

        # æ­£æ–‡ (æˆªæ–­)
        text = content[:500] if content else ""
        if text:
            lines.append(text)
            if len(content or "") > 500:
                lines.append("...")
            lines.append("")

        # ä½œè€…å’Œäº’åŠ¨
        lines.append(f"{source_emoji} @{author}")
        if metrics:
            parts = []
            if metrics.get("likes"):
                parts.append(f"â¤ï¸ {metrics['likes']}")
            if metrics.get("retweets"):
                parts.append(f"ğŸ”„ {metrics['retweets']}")
            if metrics.get("views"):
                parts.append(f"ğŸ‘ï¸ {_format_number(metrics['views'])}")
            if metrics.get("replies"):
                parts.append(f"ğŸ’¬ {metrics['replies']}")
            if parts:
                lines.append(" | ".join(parts))

        # AI åˆ†ææ‘˜è¦
        if ai_analysis:
            lines.append("")
            lines.append("---")
            lines.append("ğŸ¤– **AI åˆ†æ**")
            if isinstance(ai_analysis, dict):
                if ai_analysis.get("summary"):
                    lines.append(f"ğŸ“ {ai_analysis['summary']}")
                if ai_analysis.get("key_points"):
                    for point in ai_analysis["key_points"][:3]:
                        lines.append(f"â€¢ {point}")
                if ai_analysis.get("importance"):
                    lines.append(f"â­ é‡è¦æ€§: {ai_analysis['importance']}/10")

        # é“¾æ¥
        if url:
            lines.append("")
            lines.append(f"[æŸ¥çœ‹åŸæ–‡]({url})")

        return "\n".join(lines)

    @staticmethod
    def build_daily_report(
        contents: list[dict],
        date: Optional[datetime] = None,
        ai_summary: Optional[dict] = None,
    ) -> str:
        """æ„å»ºæ—¥æŠ¥æ¶ˆæ¯"""
        if date is None:
            date = get_local_time()

        date_str = date.strftime("%Y-%m-%d")
        lines = [f"ğŸ“Š **InfoHunter æ—¥æŠ¥** ({date_str})", ""]

        # ç»Ÿè®¡
        twitter_count = sum(1 for c in contents if c.get("source") == "twitter")
        youtube_count = sum(1 for c in contents if c.get("source") == "youtube")
        lines.append(f"ğŸ“ˆ ä»Šæ—¥é‡‡é›†: **{len(contents)}** æ¡")
        if twitter_count:
            lines.append(f"  ğŸ¦ Twitter: {twitter_count} æ¡")
        if youtube_count:
            lines.append(f"  ğŸ“º YouTube: {youtube_count} æ¡")
        lines.append("")

        # AI è¶‹åŠ¿æ€»ç»“
        if ai_summary:
            lines.append("---")
            lines.append("ğŸ¤– **AI è¶‹åŠ¿åˆ†æ**")
            if isinstance(ai_summary, dict):
                if ai_summary.get("overall_summary"):
                    lines.append(ai_summary["overall_summary"])
                if ai_summary.get("hot_topics"):
                    lines.append("")
                    lines.append("ğŸ”¥ **çƒ­é—¨è¯é¢˜**")
                    for topic in ai_summary["hot_topics"][:5]:
                        if isinstance(topic, dict):
                            lines.append(f"â€¢ {topic.get('topic', topic)}")
                        else:
                            lines.append(f"â€¢ {topic}")
                if ai_summary.get("key_insights"):
                    lines.append("")
                    lines.append("ğŸ’¡ **å…³é”®æ´å¯Ÿ**")
                    for insight in ai_summary["key_insights"][:5]:
                        lines.append(f"â€¢ {insight}")
            lines.append("")

        # Top å†…å®¹åˆ—è¡¨
        lines.append("---")
        lines.append("ğŸ“‹ **ç²¾é€‰å†…å®¹ Top 10**")
        lines.append("")

        for i, item in enumerate(contents[:10], 1):
            source_emoji = {"twitter": "ğŸ¦", "youtube": "ğŸ“º"}.get(
                item.get("source", ""), "ğŸ“°"
            )
            title = item.get("title") or (item.get("content", "")[:80] + "...")
            author = item.get("author", "unknown")
            url = item.get("url", "")

            line = f"{i}. {source_emoji} **{title}**"
            if author:
                line += f" - @{author}"
            if url:
                line += f" [é“¾æ¥]({url})"
            lines.append(line)

        now = get_local_time()
        lines.append("")
        lines.append(f"â° ç”Ÿæˆæ—¶é—´: {now.strftime('%Y-%m-%d %H:%M')}")

        return "\n".join(lines)

    @staticmethod
    def build_weekly_report(
        contents: list[dict],
        week_start: datetime,
        week_end: datetime,
        ai_summary: Optional[dict] = None,
    ) -> str:
        """æ„å»ºå‘¨æŠ¥æ¶ˆæ¯"""
        lines = [
            f"ğŸ“Š **InfoHunter å‘¨æŠ¥** ({week_start.strftime('%m/%d')} - {week_end.strftime('%m/%d')})",
            "",
        ]

        twitter_count = sum(1 for c in contents if c.get("source") == "twitter")
        youtube_count = sum(1 for c in contents if c.get("source") == "youtube")

        lines.append(f"ğŸ“ˆ æœ¬å‘¨é‡‡é›†: **{len(contents)}** æ¡")
        if twitter_count:
            lines.append(f"  ğŸ¦ Twitter: {twitter_count} æ¡")
        if youtube_count:
            lines.append(f"  ğŸ“º YouTube: {youtube_count} æ¡")
        lines.append("")

        # æ´»è·ƒä½œè€…ç»Ÿè®¡
        authors: dict[str, int] = {}
        for c in contents:
            author = c.get("author", "")
            if author:
                authors[author] = authors.get(author, 0) + 1
        if authors:
            top_authors = sorted(authors.items(), key=lambda x: x[1], reverse=True)[:5]
            lines.append("ğŸ‘¤ **æ´»è·ƒä½œè€… Top 5**")
            for author, count in top_authors:
                lines.append(f"  â€¢ @{author} ({count} æ¡)")
            lines.append("")

        # AI è¶‹åŠ¿åˆ†æ
        if ai_summary and isinstance(ai_summary, dict):
            lines.append("---")
            lines.append("ğŸ¤– **AI å‘¨åº¦è¶‹åŠ¿åˆ†æ**")
            if ai_summary.get("overall_summary"):
                lines.append(ai_summary["overall_summary"])

            if ai_summary.get("hot_topics"):
                lines.append("")
                lines.append("ğŸ”¥ **çƒ­é—¨è¯é¢˜**")
                for topic in ai_summary["hot_topics"][:5]:
                    if isinstance(topic, dict):
                        heat = topic.get("heat", "")
                        desc = topic.get("description", "")
                        name = topic.get("topic", str(topic))
                        heat_bar = "ğŸŸ¥" * min(int(heat), 10) if heat else ""
                        lines.append(f"  â€¢ **{name}** {heat_bar}")
                        if desc:
                            lines.append(f"    {desc}")
                    else:
                        lines.append(f"  â€¢ {topic}")

            if ai_summary.get("key_insights"):
                lines.append("")
                lines.append("ğŸ’¡ **å…³é”®æ´å¯Ÿ**")
                for insight in ai_summary["key_insights"][:5]:
                    lines.append(f"  â€¢ {insight}")

            if ai_summary.get("emerging_trends"):
                lines.append("")
                lines.append(f"ğŸš€ **æ–°å…´è¶‹åŠ¿**: {ai_summary['emerging_trends']}")

            if ai_summary.get("sentiment_overview"):
                sentiment_map = {
                    "positive": "ğŸ˜Š ç§¯æ",
                    "negative": "ğŸ˜Ÿ æ¶ˆæ",
                    "neutral": "ğŸ˜ ä¸­æ€§",
                    "mixed": "ğŸ”€ æ··åˆ",
                }
                sentiment = sentiment_map.get(
                    ai_summary["sentiment_overview"],
                    ai_summary["sentiment_overview"],
                )
                lines.append(f"ğŸ­ **æ•´ä½“æƒ…ç»ª**: {sentiment}")

            if ai_summary.get("recommendation"):
                lines.append(f"ğŸ’¡ **å»ºè®®å…³æ³¨**: {ai_summary['recommendation']}")
            lines.append("")

        # Top å†…å®¹
        lines.append("---")
        lines.append("ğŸ† **æœ¬å‘¨ Top 15 å†…å®¹**")
        lines.append("")

        for i, item in enumerate(contents[:15], 1):
            source_emoji = {"twitter": "ğŸ¦", "youtube": "ğŸ“º"}.get(
                item.get("source", ""), "ğŸ“°"
            )
            title = item.get("title") or (item.get("content", "")[:80] + "...")
            author = item.get("author", "")
            url = item.get("url", "")
            line = f"{i}. {source_emoji} **{title}**"
            if author:
                line += f" - @{author}"
            if url:
                line += f" [é“¾æ¥]({url})"
            lines.append(line)

        now = get_local_time()
        lines.append("")
        lines.append(f"â° ç”Ÿæˆæ—¶é—´: {now.strftime('%Y-%m-%d %H:%M')}")

        return "\n".join(lines)


def _format_number(n: int) -> str:
    """æ ¼å¼åŒ–æ•°å­— (1000 -> 1K, 1000000 -> 1M)"""
    if n >= 1_000_000:
        return f"{n / 1_000_000:.1f}M"
    if n >= 1_000:
        return f"{n / 1_000:.1f}K"
    return str(n)
